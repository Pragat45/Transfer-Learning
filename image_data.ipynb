{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a965156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.layers import Conv2D, Dense, BatchNormalization, Activation, Dropout, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371ba62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(directory):\n",
    "    directory= directory.replace('.DS_Store', '')\n",
    "    print(directory)\n",
    "    Images = []\n",
    "    Labels = []  \n",
    "    for labels in os.listdir(directory): #Main Directory where each class label is present as folder name.\n",
    "        print(labels)\n",
    "        if labels=='.DS_Store':\n",
    "            print(labels)\n",
    "        else:\n",
    "            for image_file in os.listdir(directory+labels): #Extracting the file name of the image from Class Label folder\n",
    "                image = cv2.imread(directory+labels+r'/'+image_file) #Reading the image (OpenCV)\n",
    "                image = cv2.resize(image,(224,224)) #Resize the image, Some images are different sizes. (Resizing is very Important)\n",
    "                Images.append(image)\n",
    "                Labels.append(labels)\n",
    "\n",
    "    return shuffle(Images,Labels,random_state=817328462) #Shuffle the dataset you just prepared.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790a5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//Users//pragatpagariya//Desktop//NCI//sem2//ML//project //archive (12)//train//\n",
      "happy\n",
      ".DS_Store\n",
      ".DS_Store\n",
      "sad\n",
      "fearful\n",
      "neutral\n",
      "angry\n",
      "disgusted\n",
      "surprised\n"
     ]
    }
   ],
   "source": [
    "#Train data\n",
    "test, test_label = get_images(\"//Users//pragatpagariya//Desktop//NCI//sem2//ML//project //archive (12)//train//\") #Extract the training images from the folders.\n",
    "\n",
    "test = np.array(test) #converting the list of images to numpy array.\n",
    "test_label = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79b4077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         ...,\n",
       "         [ 35,  35,  35],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32]],\n",
       "\n",
       "        [[157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         ...,\n",
       "         [ 34,  34,  34],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32]],\n",
       "\n",
       "        [[157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         ...,\n",
       "         [ 37,  37,  37],\n",
       "         [ 34,  34,  34],\n",
       "         [ 34,  34,  34]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [204, 204, 204],\n",
       "         ...,\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160]],\n",
       "\n",
       "        [[204, 204, 204],\n",
       "         [204, 204, 204],\n",
       "         [205, 205, 205],\n",
       "         ...,\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160]],\n",
       "\n",
       "        [[204, 204, 204],\n",
       "         [204, 204, 204],\n",
       "         [204, 204, 204],\n",
       "         ...,\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160]]],\n",
       "\n",
       "\n",
       "       [[[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [ 43,  43,  43],\n",
       "         [ 44,  44,  44],\n",
       "         [ 44,  44,  44]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [ 43,  43,  43],\n",
       "         [ 44,  44,  44],\n",
       "         [ 44,  44,  44]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [ 42,  42,  42],\n",
       "         [ 43,  43,  43],\n",
       "         [ 43,  43,  43]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         ...,\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173]],\n",
       "\n",
       "        [[ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         ...,\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173]],\n",
       "\n",
       "        [[ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         ...,\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173]]],\n",
       "\n",
       "\n",
       "       [[[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       "\n",
       "        [[188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       "\n",
       "        [[188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         ...,\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49]],\n",
       "\n",
       "        [[177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         ...,\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49]],\n",
       "\n",
       "        [[177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         ...,\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         ...,\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147]],\n",
       "\n",
       "        [[169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         ...,\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147]],\n",
       "\n",
       "        [[169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         ...,\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147]]],\n",
       "\n",
       "\n",
       "       [[[215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       "\n",
       "        [[215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       "\n",
       "        [[215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [196, 196, 196],\n",
       "         [196, 196, 196]],\n",
       "\n",
       "        [[197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197]],\n",
       "\n",
       "        [[197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197]]],\n",
       "\n",
       "\n",
       "       [[[ 37,  37,  37],\n",
       "         [ 37,  37,  37],\n",
       "         [ 36,  36,  36],\n",
       "         ...,\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        [[ 37,  37,  37],\n",
       "         [ 37,  37,  37],\n",
       "         [ 36,  36,  36],\n",
       "         ...,\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        [[ 36,  36,  36],\n",
       "         [ 36,  36,  36],\n",
       "         [ 36,  36,  36],\n",
       "         ...,\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         ...,\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29]],\n",
       "\n",
       "        [[ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         ...,\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29]],\n",
       "\n",
       "        [[ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         ...,\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29]]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e51dda0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example NumPy array\n",
    "arr = np.array([test])\n",
    "\n",
    "# Convert NumPy array to tuple\n",
    "arr_tuple = tuple(arr)\n",
    "\n",
    "# Now you can use arr_tuple as a key in dictionaries or sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b13677ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         ...,\n",
       "         [ 35,  35,  35],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32]],\n",
       "\n",
       "        [[157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         ...,\n",
       "         [ 34,  34,  34],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32]],\n",
       "\n",
       "        [[157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         [157, 157, 157],\n",
       "         ...,\n",
       "         [ 37,  37,  37],\n",
       "         [ 34,  34,  34],\n",
       "         [ 34,  34,  34]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[203, 203, 203],\n",
       "         [203, 203, 203],\n",
       "         [204, 204, 204],\n",
       "         ...,\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160]],\n",
       "\n",
       "        [[204, 204, 204],\n",
       "         [204, 204, 204],\n",
       "         [205, 205, 205],\n",
       "         ...,\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160]],\n",
       "\n",
       "        [[204, 204, 204],\n",
       "         [204, 204, 204],\n",
       "         [204, 204, 204],\n",
       "         ...,\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160],\n",
       "         [160, 160, 160]]],\n",
       "\n",
       "\n",
       "       [[[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [ 43,  43,  43],\n",
       "         [ 44,  44,  44],\n",
       "         [ 44,  44,  44]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [ 43,  43,  43],\n",
       "         [ 44,  44,  44],\n",
       "         [ 44,  44,  44]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [ 42,  42,  42],\n",
       "         [ 43,  43,  43],\n",
       "         [ 43,  43,  43]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         ...,\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173]],\n",
       "\n",
       "        [[ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         ...,\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173]],\n",
       "\n",
       "        [[ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         [ 74,  74,  74],\n",
       "         ...,\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173],\n",
       "         [173, 173, 173]]],\n",
       "\n",
       "\n",
       "       [[[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169]],\n",
       "\n",
       "        [[ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         [ 56,  56,  56],\n",
       "         ...,\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168],\n",
       "         [168, 168, 168]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       "\n",
       "        [[188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]],\n",
       "\n",
       "        [[188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         [188, 188, 188],\n",
       "         ...,\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200],\n",
       "         [200, 200, 200]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         ...,\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49]],\n",
       "\n",
       "        [[177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         ...,\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49]],\n",
       "\n",
       "        [[177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         [177, 177, 177],\n",
       "         ...,\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49],\n",
       "         [ 49,  49,  49]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         ...,\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147]],\n",
       "\n",
       "        [[169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         ...,\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147]],\n",
       "\n",
       "        [[169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         [169, 169, 169],\n",
       "         ...,\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147],\n",
       "         [147, 147, 147]]],\n",
       "\n",
       "\n",
       "       [[[215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       "\n",
       "        [[215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       "\n",
       "        [[215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         [215, 215, 215],\n",
       "         ...,\n",
       "         [116, 116, 116],\n",
       "         [119, 119, 119],\n",
       "         [119, 119, 119]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         ...,\n",
       "         [194, 194, 194],\n",
       "         [196, 196, 196],\n",
       "         [196, 196, 196]],\n",
       "\n",
       "        [[197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197]],\n",
       "\n",
       "        [[197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197],\n",
       "         ...,\n",
       "         [195, 195, 195],\n",
       "         [197, 197, 197],\n",
       "         [197, 197, 197]]],\n",
       "\n",
       "\n",
       "       [[[ 37,  37,  37],\n",
       "         [ 37,  37,  37],\n",
       "         [ 36,  36,  36],\n",
       "         ...,\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        [[ 37,  37,  37],\n",
       "         [ 37,  37,  37],\n",
       "         [ 36,  36,  36],\n",
       "         ...,\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        [[ 36,  36,  36],\n",
       "         [ 36,  36,  36],\n",
       "         [ 36,  36,  36],\n",
       "         ...,\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         ...,\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29]],\n",
       "\n",
       "        [[ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         ...,\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29]],\n",
       "\n",
       "        [[ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         [ 32,  32,  32],\n",
       "         ...,\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29],\n",
       "         [ 29,  29,  29]]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb9e56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sad': 4830,\n",
       "         'fearful': 4097,\n",
       "         'neutral': 4965,\n",
       "         'surprised': 3171,\n",
       "         'angry': 3995,\n",
       "         'happy': 7215,\n",
       "         'disgusted': 436})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cdc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6429b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = len(test)\n",
    "data_imagesRGB = test.reshape((n_samples, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a8cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_imagesRGB, test_label, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8310d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3cc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier(max_depth=300)\n",
    "dt.fit(X_train,y_train)\n",
    "yhat_classes = dt.predict(X_test)\n",
    "print(classification_report(y_test, yhat_classes))\n",
    "print(confusion_matrix(y_test, yhat_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0160fc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.25      0.22      0.23       836\n",
      "   disgusted       0.22      0.25      0.24        91\n",
      "     fearful       0.29      0.28      0.29       835\n",
      "       happy       0.38      0.50      0.43      1426\n",
      "     neutral       0.26      0.39      0.31       936\n",
      "         sad       0.32      0.17      0.22       989\n",
      "   surprised       0.53      0.30      0.38       629\n",
      "\n",
      "    accuracy                           0.32      5742\n",
      "   macro avg       0.32      0.30      0.30      5742\n",
      "weighted avg       0.33      0.32      0.32      5742\n",
      "\n",
      "[[180  11 101 237 195  88  24]\n",
      " [  7  23   9  24  20   3   5]\n",
      " [112  11 234 213 146  67  52]\n",
      " [119  24 133 715 300  96  39]\n",
      " [121  10  93 260 363  65  24]\n",
      " [119  15 143 275 249 165  23]\n",
      " [ 56   9  91 143 112  32 186]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=7) \n",
    "knn.fit(X_train,y_train)\n",
    "yhat_classes = knn.predict(X_test)\n",
    "print(classification_report(y_test, yhat_classes))\n",
    "print(confusion_matrix(y_test, yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ba343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"RF\")\n",
    "rfc = RandomForestClassifier(n_estimators=300, max_depth=300)  \n",
    "rfc.fit(X_train, y_train)\n",
    "# calculate accuracy of class predictions\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test, yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7e0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Loading pytorch packages.\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6bb139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-large-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Use the 124-layer, 1024-hidden, 16-heads, 340M parameters BERT model with an uncased vocab.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# The number of output labels--2 for binary classification. You can increase this for multi-class tasks.   \u001b[39;00m\n\u001b[1;32m      4\u001b[0m     output_attentions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Whether the model returns attentions weights.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     output_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Whether the model returns all hidden-states.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Tell pytorch to run this model on the device which we set GPU in our case.\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-large-uncased', # Use the 124-layer, 1024-hidden, 16-heads, 340M parameters BERT model with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification. You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the device which we set GPU in our case.\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d16c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed668d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensors = torch.tensor(test.transpose(0, 3, 1, 2))  # Convert image arrays to PyTorch tensors\n",
    "\n",
    "# Step 4: Perform inference using the pre-trained model\n",
    "with torch.no_grad():\n",
    "    outputs = model(pixel_values=image_tensors)  # Perform inference on the image tensors\n",
    "\n",
    "# Step 5: Extract predictions\n",
    "predictions = outputs.logits.softmax(dim=-1)  # Get softmax probabilities for each class\n",
    "predicted_classes = torch.argmax(predictions, dim=-1)  # Get predicted class labels\n",
    "\n",
    "# Step 6: Print predicted classes\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea64bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
